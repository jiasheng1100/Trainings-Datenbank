{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b2lZToCpdEm"
      },
      "source": [
        "Sheet 3.1: Gradient descent by hand\n",
        "===================================\n",
        "\n",
        "**Author:** Michael Franke\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7HWe0KtpdEy"
      },
      "source": [
        "This short notebook will optimize a parameter with gradient descent without using PyTorch&rsquo;s optimizer.\n",
        "The purpose of this is to demonstrate how vanilla GD works under the hood.\n",
        "We use the previous example of finding the MLE for a Gaussian mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Student: Jia Sheng (5371477)"
      ],
      "metadata": {
        "id": "020al7lUxQq6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ9AsQmqpdE0"
      },
      "source": [
        "## Packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Evl_rD4pdE2"
      },
      "source": [
        "We will need the usual packages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_YreIyHwpdE3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7D4mBNDpdE8"
      },
      "source": [
        "## Training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaWAc4GkpdE-"
      },
      "source": [
        "The training data are \\`nObs\\` samples from a standard normal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SyUSogwmpdFA"
      },
      "outputs": [],
      "source": [
        "nObs           = 10000\n",
        "trueLocation   = 0 # mean of a normal\n",
        "trueDist       = torch.distributions.Normal(loc=trueLocation, scale=1.0)\n",
        "trainData      = trueDist.sample([nObs])\n",
        "empirical_mean = torch.mean(trainData)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bko-b712pdFC"
      },
      "source": [
        "## Training by manual gradient descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrsu4nZdpdFF"
      },
      "source": [
        "We will actually train two parameters on the same data in parallel.\n",
        "\\`location\\` will be updated by hand; \\`location2\\` will be updated with PyTorch&rsquo;s \\`SGD\\` optimizer.\n",
        "We will use the same learning rate for both.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TNmuuzuspdFH"
      },
      "outputs": [],
      "source": [
        "location       = torch.tensor(1.0, requires_grad=True)\n",
        "location2      = torch.tensor(1.0, requires_grad=True)\n",
        "learningRate   = 0.00001\n",
        "nTrainingSteps = 100\n",
        "opt = torch.optim.SGD([location2], lr = learningRate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05VrchxKpdFJ"
      },
      "source": [
        "The training loop here first updates by hand, then using the built-in\\`SGD\\`.\n",
        "Every 5 rounds we output the current value of \\`location\\` and \\`location2\\`, as well as the difference between them.\n",
        "\n",
        "But, oh no! What&rsquo;s this? There must be a bunch of mistakes in this code! See Exercise below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XHE7_dR0pdFL",
        "outputId": "74c3e2a1-3de5-4149-bd25-f1da5ae2e507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " step        estimate       estimate2      difference\n",
            "\n",
            "    5 0.59379917383194 0.59379917383194 0.00000000000000\n",
            "\n",
            "   10 0.35394167900085 0.35394167900085 0.00000000000000\n",
            "\n",
            "   15 0.21230822801590 0.21230821311474 0.00000001490116\n",
            "\n",
            "   20 0.12867507338524 0.12867507338524 0.00000000000000\n",
            "\n",
            "   25 0.07929053902626 0.07929053902626 0.00000000000000\n",
            "\n",
            "   30 0.05012946203351 0.05012946203351 0.00000000000000\n",
            "\n",
            "   35 0.03291014209390 0.03291013836861 0.00000000372529\n",
            "\n",
            "   40 0.02274230308831 0.02274230122566 0.00000000186265\n",
            "\n",
            "   45 0.01673829928041 0.01673829741776 0.00000000186265\n",
            "\n",
            "   50 0.01319299172610 0.01319298986346 0.00000000186265\n",
            "\n",
            "   55 0.01109952386469 0.01109952200204 0.00000000186265\n",
            "\n",
            "   60 0.00986335054040 0.00986334867775 0.00000000186265\n",
            "\n",
            "   65 0.00913339667022 0.00913339760154 -0.00000000093132\n",
            "\n",
            "   70 0.00870237313211 0.00870237313211 0.00000000000000\n",
            "\n",
            "   75 0.00844785757363 0.00844785757363 0.00000000000000\n",
            "\n",
            "   80 0.00829756539315 0.00829756539315 0.00000000000000\n",
            "\n",
            "   85 0.00820882152766 0.00820882152766 0.00000000000000\n",
            "\n",
            "   90 0.00815641973168 0.00815641973168 0.00000000000000\n",
            "\n",
            "   95 0.00812547653913 0.00812547653913 0.00000000000000\n",
            "\n",
            "  100 0.00810720678419 0.00810720678419 0.00000000000000\n"
          ]
        }
      ],
      "source": [
        "print('\\n%5s %15s %15s %15s' %\n",
        "      (\"step\", \"estimate\", \"estimate2\", \"difference\") )\n",
        "\n",
        "for i in range(nTrainingSteps):\n",
        "\n",
        "    # manual computation\n",
        "    prediction = torch.distributions.Normal(loc=location, scale=1.0)\n",
        "    loss       = -torch.sum(prediction.log_prob(trainData))\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        # we must embedd this under 'torch.no_grad()' b/c we\n",
        "        # do not want this update state to affect the gradients\n",
        "        location  -= learningRate * location.grad\n",
        "    location.grad = torch.tensor(0.0)\n",
        "\n",
        "    # using PyTorch optimizer\n",
        "    prediction2 = torch.distributions.Normal(loc=location2, scale=1.0)\n",
        "    loss2       = -torch.sum(prediction2.log_prob(trainData))\n",
        "    loss2.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # print output\n",
        "    if (i+1) % 5 == 0:\n",
        "        print('\\n%5s %-2.14f %-2.14f %2.14f' %\n",
        "              (i + 1, location.item(), location2.item(),\n",
        "               location.item() - location2.item()) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-3KwrUpdFP"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 3.1.1: Understand vanilla gradient descent</span></strong>\n",
        ">\n",
        "> Find and correct all mistakes in this code block.\n",
        "> When you are done, the parameters should show no difference at any update step, and they should both converge to the empirical mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer to Exercise 3.1.1\n",
        "see the code block above where 2 mistakes in code are corrected."
      ],
      "metadata": {
        "id": "qCfQ7qj8wxpx"
      }
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}